<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Vocal Canceler | Audio Signal Processing by WebAssembly</title>
    <link rel="stylesheet" href="../app.css" />
  </head>
  <body>
    <section>
      <nav><a href="../">TOP</a> &gt; &gt; Vocal Canceler</nav>
      <dt>
        <dt><label for="file-uploader">Upload Audio File</label></dt>
        <dd><input type="file" id="file-uploader" /></dd>
        <dt><label for="range-depth">Depth: <span id="output-depth">0</span></label></dt>
        <dd><input type="range" id="range-depth" value="0" min="0" max="1" step="0.05" /></dd>
      </dt>
    </section>
    <script>
      const numberOfChannels = 2;

      let audio = null;
      let depth = 0;

      WebAssembly
        .instantiateStreaming(fetch('./vocalcanceler.wasm'))
        .then(({ instance }) => {
          const audiocontext = new AudioContext();
          const processor    = audiocontext.createScriptProcessor(0, numberOfChannels, numberOfChannels);

          document.getElementById('file-uploader').addEventListener('change', async (event) => {
            processor.onaudioprocess = null;
            processor.disconnect(0);

            if (audio) {
              audio.pause();
            }

            try {
              await audiocontext.resume();

              const objectURL = window.URL.createObjectURL(event.target.files[0]);

              audio = new Audio(objectURL);

              const source = audiocontext.createMediaElementSource(audio);

              source.connect(processor);
              processor.connect(audiocontext.destination);

              const bufferSize = processor.bufferSize;

              const linearMemory = instance.exports.memory.buffer;

              processor.onaudioprocess = (event) => {
                const inputLs  = event.inputBuffer.getChannelData(0);
                const inputRs  = event.inputBuffer.getChannelData(1);
                const outputLs = event.outputBuffer.getChannelData(0);
                const outputRs = event.outputBuffer.getChannelData(1);

                const inputOffsetL = instance.exports.alloc_memory_inputLs(bufferSize);
                const inputOffsetR = instance.exports.alloc_memory_inputRs(bufferSize);

                const inputLinearMemoryLs = new Float32Array(linearMemory, inputOffsetL, bufferSize);
                const inputLinearMemoryRs = new Float32Array(linearMemory, inputOffsetR, bufferSize);

                inputLinearMemoryLs.set(inputLs);
                inputLinearMemoryRs.set(inputRs);

                const outputOffsetL = instance.exports.vocalcancelerL(depth, bufferSize);
                const outputOffsetR = instance.exports.vocalcancelerR(depth, bufferSize);

                outputLs.set(new Float32Array(linearMemory, outputOffsetL, bufferSize));
                outputRs.set(new Float32Array(linearMemory, outputOffsetR, bufferSize));
              };

              audio.play();
            } catch (e) {
              console.error(e);
            }
          }, false);

          document.getElementById('range-depth').addEventListener('input', (event) => {
            const range = event.currentTarget;

            depth = range.valueAsNumber;

            document.getElementById('output-depth').textContent = range.value;
          }, false);
        })
        .catch(console.error);
    </script>
  </body>
</html>
